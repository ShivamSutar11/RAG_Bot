ğŸ“˜ Local RAG Chatbot (Qwen 0.5B + MiniLM + FAISS)

A lightweight, document-restricted RAG chatbot that runs fully locally.
Built using Qwen 0.5B, MiniLM embeddings, FAISS vector search, and LangChain utilities.

Fast, clean, and surprisingly smooth â€” even on CPU/MPS machines.

ğŸš€ Features
ğŸ”’ Document-Restricted RAG

The bot answers only from your uploaded documents (PDFs/TXTs).
If the answer isnâ€™t found, it simply says:

â€œI cannot find that information in the context.â€

ğŸ¤– Strict Extractive Mode

No hallucinations.
No unwanted explanations.
No extra paragraphs.

âš¡ Lightweight Local Pipeline

Qwen 0.5B â€” small, fast, responsive

MiniLM-L6-v2 â€” compact but accurate embeddings

FAISS â€” high-speed vector search

LangChain loaders + splitter for PDF/TXT ingestion

ğŸ–¥ï¸ Runs Fully Offline

No APIs. No cloud. Everything happens on your machine.

ğŸ› ï¸ Architecture Overview

Load documents (PDF/Text) using LangChain loaders

Split content using RecursiveCharacterTextSplitter

Embed chunks with MiniLM

Store + index them in FAISS

Embed user query

Retrieve top-k relevant chunks

Feed strict context + system prompt into Qwen

Generate extractive answer

ğŸ“ Project Structure
RAG_Bot/
â”‚â”€â”€ docs/                 # Your PDFs or text files
â”‚â”€â”€ rag_engine.py         # RAG pipeline logic
â”‚â”€â”€ ui_app.py             # Gradio UI
â”‚â”€â”€ rag_env/              # Virtual environment (optional)
â”‚â”€â”€ README.md

â–¶ï¸ Getting Started
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Add documents

Place PDFs or text files inside:

/docs

3ï¸âƒ£ Run the app
python ui_app.py


Then open the provided local URL in your browser.

ğŸ§© Technologies Used
Component	Choice	Why
LLM	Qwen2.5-0.5B-Instruct	Fast, lightweight, great quality for small size
Embeddings	MiniLM-L6-v2	Accurate, tiny, fast for local RAG
Vector Store	FAISS	Super fast similarity search
Framework	LangChain	Easy document loading + vector DB integration
UI	Gradio	Quick, smooth local interface
ğŸ˜… Challenges I Faced

System prompt chaos:
The model kept echoing long chunks and explaining concepts I never asked for.

LangChain retrieval quirks:
Even with FAISS and splitting, retrieval sometimes returned odd chunks until fine-tuned.

Needed strict RAG enforcement:
Without rules, the model behaved like it was writing a thesis.

Choosing the right model:
Qwen 0.5B ended up much more stable and responsive than other small LLMs (Flan-T5, Gemma-2B, etc.).

But now the bot listens.
Until it decides not to. ğŸ˜ŒğŸ¤–

ğŸ“Œ Notes

This chatbot is strictly document-bound â€” no outside knowledge.

Works fully offline once the models are downloaded.

Perfect for study notes, research papers, or private knowledge bases.

â­ Future Improvements

Add multi-document RAG ranking

Add citation highlights

Add chat history memory

Add GPU acceleration for embeddings

TO Run app : http://127.0.0.1:7860
